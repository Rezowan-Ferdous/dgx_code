{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision import transforms\n",
    "import torch,os\n",
    "import torch.nn.functional as F\n",
    "import cv2 \n",
    "\n",
    "cholec_root= \"/home/ubuntu/Dropbox/Datasets/cholec80\"\n",
    "\n",
    "PHASES = [\n",
    "    \"Preparation\",\n",
    "    \"CalotTriangleDissection\",\n",
    "    \"ClippingCutting\",\n",
    "    \"GallbladderDissection\",\n",
    "    \"GallbladderRetraction\",\n",
    "    \"CleaningCoagulation\",\n",
    "    \"GallbladderPackaging\"\n",
    "]\n",
    "\n",
    "action_dict= {\"Preparation\":0,\n",
    "    \"CalotTriangleDissection\":1,\n",
    "    \"ClippingCutting\":2,\n",
    "    \"GallbladderDissection\":3,\n",
    "    \"GallbladderRetraction\":4,\n",
    "    \"CleaningCoagulation\":5,\n",
    "    \"GallbladderPackaging\":6}\n",
    "\n",
    "def get_video_prop(path):\n",
    "    \"\"\"Get properties of a video\"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    cap.release()\n",
    "    return dict(fps=fps, num_frames=num_frames, height=height, width=width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_name(file):\n",
    "    return file.split('-timestamp')[0].split('.')[0]\n",
    "\n",
    "def make_cholecdf(cholec_root):\n",
    "    video_files = []\n",
    "    phase_annotations = []\n",
    "    tool_annotations = []\n",
    "    feature_files = []\n",
    "    num_frames = []\n",
    "    fps = []\n",
    "    videos_path = os.path.join(cholec_root, 'videos')\n",
    "    phases_path = os.path.join(cholec_root, 'phase_annotations')\n",
    "    tools_path = os.path.join(cholec_root, 'tool_annotations')\n",
    "    features_path = os.path.join(cholec_root, 'features')\n",
    "\n",
    "\n",
    "    video_list = [f for f in os.listdir(videos_path) if f.endswith('.mp4')]\n",
    "    phase_list= os.listdir(phases_path)\n",
    "    tool_list= os.listdir(tools_path)\n",
    "    feature_list= os.listdir(features_path)\n",
    "\n",
    "    # Match video names with the corresponding annotations and features\n",
    "    for video_file in video_list:\n",
    "        base_name = get_base_name(video_file)\n",
    "\n",
    "        # Find corresponding phase annotation, tool annotation, and feature files\n",
    "        phase_file = next((f for f in phase_list if get_base_name(f) == base_name), None)\n",
    "\n",
    "        # Initialize variables\n",
    "        segments = []  # List to hold the segments\n",
    "        start_frame = 0  # Starting frame for the first segment\n",
    "        prev_phase = None  # Previous phase to track changes\n",
    "\n",
    "        with open(phase_file, \"r\") as f:\n",
    "            gt = f.read().split(\"\\n\")[1:-1]\n",
    "        gt_array = np.full(len(gt), -100)\n",
    "        for i in range(len(gt)):\n",
    "            # gt_array[i] = action_dict[gt[i].split(\"\\t\")[-1]]\n",
    "            # print(gt[i], action_dict[gt[i]], gt_array[i])\n",
    "            # Get the frame and phase from the line\n",
    "            frame_data = gt[i].split(\"\\t\")\n",
    "            current_frame = int(frame_data[0])  # Frame number\n",
    "            current_phase = frame_data[-1]  # Phase name\n",
    "\n",
    "            # Map the phase to its corresponding action index\n",
    "            if current_phase in action_dict:\n",
    "                gt_array[i] = action_dict[current_phase]\n",
    "\n",
    "                # Track phase changes\n",
    "                if prev_phase is None:\n",
    "                    # Initialize the previous phase\n",
    "                    prev_phase = current_phase\n",
    "                    start_frame = current_frame  # Start segment at the first frame\n",
    "                elif current_phase != prev_phase:\n",
    "                    # When phase changes, record the previous phase segment\n",
    "                    segments.append({\n",
    "                        'start_frame': start_frame,\n",
    "                        'end_frame': current_frame - 1,\n",
    "                        'phase': prev_phase,\n",
    "                        'action': action_dict[prev_phase]\n",
    "                    })\n",
    "                    # Reset start frame and previous phase\n",
    "                    start_frame = current_frame\n",
    "                    prev_phase = current_phase\n",
    "\n",
    "            # After loop, check if there's an active segment to close\n",
    "        if prev_phase is not None:\n",
    "            segments.append({\n",
    "                'start_frame': start_frame,\n",
    "                'end_frame': current_frame,  # Last frame processed\n",
    "                'phase': prev_phase,\n",
    "                'action': action_dict[prev_phase]\n",
    "            })\n",
    "\n",
    "        tool_file = next((f for f in tool_list if get_base_name(f) == base_name), None)\n",
    "        feature_file = next((f for f in feature_list if get_base_name(f) == base_name), None)\n",
    "\n",
    "        video_prop= _get_video_prop(video_file)\n",
    "        num_frame= video_prop['num_frames']\n",
    "        fp=video_prop['fps']\n",
    "        num_frames.append(num_frame)\n",
    "        fps.append(fp)\n",
    "        # Append to the lists only if all corresponding files are found\n",
    "        if phase_file and tool_file and feature_file:\n",
    "            video_files.append(os.path.join('videos', video_file))\n",
    "            phase_annotations.append(os.path.join('phase_annotations', phase_file))\n",
    "            tool_annotations.append(os.path.join('tool_annotations', tool_file))\n",
    "            feature_files.append(os.path.join('features', feature_file))\n",
    "\n",
    "    # Create a dataframe with the relevant paths\n",
    "    df = pd.DataFrame({\n",
    "        'video_file': video_files,\n",
    "        'phase_annotation': phase_annotations,\n",
    "        'tool_annotation': tool_annotations,\n",
    "        'feature_file': feature_files,\n",
    "        'num_frames':num_frames,\n",
    "        'fps':fps,\n",
    "\n",
    "    })\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "# make_cholecdf(cholec_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videoenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
